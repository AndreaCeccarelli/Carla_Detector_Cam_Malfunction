\documentclass[14pt]{extarticle}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[english]{babel}
\usepackage[final]{pdfpages}
\usepackage{imakeidx}
\usepackage{version}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{color}

\definecolor{javared}{rgb}{0.6,0,0} % for strings
\definecolor{javagreen}{rgb}{0.25,0.5,0.35} % comments
\definecolor{javapurple}{rgb}{0.5,0,0.35} % keywords
\definecolor{javadocblue}{rgb}{0.25,0.35,0.75} % javadoc
 
\lstset{language=Python,
    keywordstyle=\color{ja\tableofcontentsvapurple},
    basicstyle=\small,
    commentstyle=\color{javagreen},
    stringstyle=\color{javadocblue},
    showstringspaces=false,
    breaklines=true,
    frameround=ffff,
    frame=single,
    rulecolor=\color{black}
} 
\makeindex[columns=3, title=Alphabetical Index, intoc]
\usepackage[backend=bibtex]{biblatex}
\addbibresource{bibliografia.bib}


\begin{document}

\title{\includegraphics{download.jpeg} \vspace{2cm} \textbf{\\Tesi di Laurea}}

\author{\texttt{Pietro Bernabei} - \texttt{matricola:6291312}\\ \texttt{Anno Accademico 2019/20}}
\date{}
\maketitle
\newpage
\tableofcontents

\newpage
\section{Introduzione}
\subsection{Motivazioni}
Nel giro di un paio di secoli il mondo, è passato dal viaggiare in groppa a un cavallo, alla groppa di una macchina, dal essere il conducente, al condotto. Le macchine a guida autonoma parziali e totali stanno diventando ogni giorno che avanza, realtà. Questa rivoluzione sta permeando il nostro stile di vita, diventandone dipendenti a tal punto da richiedere che questi siano continuativi, privi da possibili errori o malfunzionamenti.

Come per un essere umano, che soffre di miopia, guidare senza occhiali è pericoloso, anche per il sistema di guida autonoma, guidare con le telecamere con guasti porta a incidenti.
Come verrà espresso in seguito, le telecamere negli attuali sistemi, ricoprono un ruolo decisivo nel momento decisionale della guida autonoma, e un loro malfunzionamento nel processo di acquisizione riperquote nel sistema decisionale, errori non molto graditi al guidatore.
\subsection{Obiettivo}
Nella seguente tesi si propone un sistema software, detto Detector, in grado di rilevare, nel flusso di immagini generate dalla telecamera di un mezzo a guida autonoma, la presenza di malfunzionamenti nel sistema di acquisizione, come congelamento, pixel bruciati,e tanti altri, per poi notificare i possibili esiti al sistema  decisionale del mezzo.
\subsection{Organizzazione del lavoro} 
Avendo definito il detector, come un sistema in grado di rilevare una variazione malevola nel flusso di immagini acquisite dalla fotocamera, questo dovrà essere in grado di classificare l'immagine sottoposta a decisione. 
Per questo la soluzione descritta,impiega una particolare forma di intelligenza artificiale,la rete neurale convuluzionale (CNN)...
Come verrà esposto meglio in seguito, una convulutional neural network è una particolare forma di supervisioned learning, particolarmente efficiente in ambienti grafici, sopratutto per la classificazione di intere immagini o identificazione di elementi al loro interno. I supervisioned learning, e quindi anche CNN richiedono una fase di training, nella quale viene definita  la propria conoscenza di base (Knowledge base), sulla quale si baserà per prendere le decisioni.
Detto ciò lo sviluppo del detector si divide in:
\begin{itemize}
\item Definizione e generazione Dataset
\item Creazione CNN
\item Training CNN
\end{itemize}

\section{Fondamenti teorici}
\subsection{Sistemi Critici}
Ogni giorno, una persona usa infrastutture, mezzi, telecumicazioni, e servizi di qualsiasi genere, affidandosi totalmente al loro funzionamento, alla loro continuità, dando per scontato che non possano subire guasti o malfunzionamenti, perchè ove questi avvengano il risultato sarebbe devastante per tutto il nostro sistema di vita. Queste componenti si definiscono come \textbf{Sistemi Critici}, e  il loro corretto funzionamento, dipende dalla nostra capacità di analizzarne aspetti quantitativi relativi sia a caratteristiche prestazionali quali velocità di elaborazione o altre misure di efficienza,
sia caratteristiche di sicurezza, disponibilità o affidabilità che dimostrino e ci
convincano della adeguatezza dei nostri manufatti per i compiti sempre più
critici e delicati per i quali li utilizziamo.

\subsubsection{Dependability}
La \textbf{dependability} è una delle proprietà fondamentali dei sistemi informatici insieme a funzionalità, usabilità, performance e costo. Per fornirne una prima definizione, è necessario illustrare i concetti di: \cite{avizienis2004basic}.
\begin{itemize}
\item \textbf{Servizio:} Il servizio fornito da un sistema è il comportamento del sistema stesso, così come viene percepito dai suoi utenti.
\item \textbf{Utente:}Un utente di un sistema è un altro sistema che interagisce attraverso l’interfaccia del servizio.
\item \textbf{Funzione di sistema:}La funzione di un sistema rappresenta che cosa ci attendiamo dal sistema; la descrizione della funzione di un sistema è fornita attraverso la sua specifica funzionale. Il servizio è detto corretto se realizza la funzione del sistema.
\end{itemize}

Detto ciò nella sua definizione originale \textbf{dependability} è
la capacità di un sistema di fornire un servizio su cui è possibile fare affidamento in
modo giustificato.\cite{bondavalli2011analisi}

Una definizione alternativa, che stabilisce un criterio per decidere se un determinato servizio è dependable, definisce la \textbf{dependability} di un sistema
come la capacità di evitare fallimenti che siano più frequenti e più severi del
limite accettabile \cite{avizienis2004basic}.

Ciò di cui la definizione precedente non tiene conto, è che il comportamento del nostro sistema, sia sempre definito nella sua totalità, senza ambiguità e precisa. 
Per questo la dependability può essere vista come una misura di quanta fiducia possiamo riporre in modo giustificato sul servizio erogato dal sistema stesso.\cite{bondavalli2011analisi}

Un’esposizione sistematica dei concetti relativi alla dependability consiste di tre parti:

\begin{itemize}
\item \textbf{Le minacce o impedimenti alla dependability.} Gli impedimenti sono le
cause potenziali di comportamenti non previsti.
\item \textbf{Gli attributi della dependability.} Gli attributi ci permettono di esprimere
e verificare il livello di dependability richiesto od ottenuto.
\item \textbf{I mezzi per ottenere la dependability.} I mezzi sono le tecniche che
permettono di ottenere comportamenti corretti, nonostante il verificarsi
degli impedimenti.
\end{itemize}

\subsubsection{Le Minacce: guasti, errori e fallimenti}
Si definisce:\cite{bondavalli2011analisi}
\begin{itemize}
\item \textbf{guasto:} la causa accertata o ipotizzata di un errore, derivante da malfunzionamenti di componenti, interferenze ambientali di natura fisica, sbagli dell’operatore o da una progettazione fallace.
\item \textbf{errore:} è la parte dello stato del sistema che può causare un susseguente fallimento; in alternativa si definisce errore la manifestazione di un guasto all’interno di un programma o di una struttura dati.
\item \textbf{fallimento:} di sistema è un evento che occorre quando un errore raggiunge l’interfaccia di servizio, alterando il servizio stesso. Quando un sistema viola la sua specifica di servizio si dice che è avvenuto un fallimento; il fallimento è quindi una transizione da un servizio corretto a un servizio non corretto. La transizione inversa, da un servizio non corretto ad uno corretto, è detta ripristino.
\end{itemize}

\subparagraph{Il guasto} può rimanere dormiente per un certo periodo, fino alla sua attivazione. L’attivazione di un guasto porta ad un errore, che è la parte dello
stato del sistema che può causare un successivo fallimento. 
I guasti di un sistema possono essere classificati secondo diversi punti di vista, ad esempio
fisico, logico e di interazione. Un’altra suddivisione può essere fatta in base
alla natura del guasto: un guasto può essere intenzionale o accidentale, malizioso oppure non malizioso; ed ancora in base alla persistenza dove abbiamo
guasti permanenti, transienti ed intermittenti. Per una tassonomia completa
si rimanda a \cite{avizienis2004basic}. \textbf{(riguarda)}


\subparagraph{Il fallimento} di un componente si verifica quando il servizio fornito devia
dalla sua specifica: si verifica nel momento in cui un errore del componente
si manifesta alla sua interfaccia, e diventa quindi un guasto per il sistema. Il
fallimento è quindi l’effetto, osservabile esternamente, di un errore nel sistema; gli errori sono in stato latente fino a che non vengono rilevati e/o non
producono un fallimento.

La deviazione dal servizio corretto può assumere diverse forme, che vengono chiamate modi di fallimento e possono venire classificati secondo la loro
gravità (severity).

\begin{comment} I modi di fallimento caratterizzano un servizio non corretto
da quattro punti di vista:
\begin{itemize}
\item Il dominio dei fallimenti,
\item La possibilità di rilevare i fallimenti,
\item La consistenza dei fallimenti,
\item Le conseguenze dei fallimenti.
\end{itemize}

Una completa analisi dei rischi (risk analysis, \cite{cenelec199950126}) e delle modalità di fallimento ad essi associate è necessaria per lo sviluppo di sistemi critici; tali
attività sono generalmente classificate come obbligatorie negli stessi standard
per la certificazione del rispetto di requisiti di dependability (ad esempio in
\cite{cenelec199950126}).
\end{comment}

Un sistema è formato da un insieme di componenti che interagiscono tra
loro, perciò lo stato del sistema è l’insieme degli stati dei suoi componenti. Un
guasto causa inizialmente un errore nello stato di uno (o più) componenti, ma
il fallimento del sistema non si verifica fino a quanto l’errore non raggiunge l’interfaccia del servizio. La propagazione di errori può permettere ad un errore
di raggiungere l’interfaccia di servizio. Questo insieme di meccanismi costituisce la catena di impedimenti guasto-errore-fallimento (fault-error-failure)
La propagazione all’interno di un componente (propagazione interna) è
causata dal processo di elaborazione: un errore viene successivamente trasformato in altri errori.
%guarda se aggiungere anche il parallelismo con carla forse è utile
\subsubsection{Gli attributi della dependability}
Il concetto di dependability è la sintesi di più attributi che forniscono misure
quantitative o qualitative del sistema:
\begin{itemize}
\item \textbf{Affidabilità (reliability):} è la capacità del sistema di erogare un servizio corretto in modo continuo; misura la fornitura continua di un servizio
corretto.
\item \textbf{Manutenibilità (maintainability):} la capacità del sistema di subire modifiche e riparazioni; misura il tempo necessario per ristabilire un servizio
corretto.
\item \textbf{Disponibilità (availability):} è la prontezza del sistema nell’erogare un
servizio corretto; misura la fornitura di servizio corretto, rispetto all’alternanza fra servizio corretto e non corretto.
\item \textbf{Confidenzialità (confidentiality):} è l’assenza di diffusione non autorizzata di informazioni; misura l’assenza di esposizione non autorizzata di
informazione.
\item \textbf{Integrità (integrity):} descrive l’assenza di alterazioni improprie del sistema; misura l’assenza di alterazioni improprie dello stato del sistema.

\item \textbf{La sicurezza (safety)} è poi l’assenza di conseguenze catastrofiche sugli
utenti e sull’ambiente circostante. La safety può essere vista come l’affidabilità
del sistema \begin{comment}, considerando come corretti anche gli stati in cui il sistema subisce
un fallimento benigno (possiamo quindi fondere in un unico stato sia gli stati
corretti che i fallimenti benigni del sistema, e valutare in questo nuovo schema
l’affidabilità)\end{comment}.
\item \textbf{sicurezza (security)} può quindi essere vista come la contemporanea esistenza di availability solo per gli utenti autorizzati, confidentiality, e
integrity, dove per “improprie” si intende “non autorizzate” \cite{nicol2004model}.
\end{itemize}
Ciascuno di questi attributi può essere più o meno importante in base all’applicazione: la disponibilità del servizio è sempre richiesta, anche se può
variare sia l’importanza relativa che il livello quantitativo richiesto mentre, la affidabilità, la safety, la confidenzialità e gli altri attributi possono essere richiesti
o meno. Nella loro definizione, la disponibilità e la affidabilità evidenziano la
capacità di evitare i fallimenti, mentre la safety e la security evidenziano la
capacità di evitare specifiche classi di fallimenti come ad esempio fallimenti
catastrofici e accesso non autorizzato alle informazioni.

I requisiti di dependability di un sistema sono forniti attraverso una descrizione degli obiettivi richiesti per uno o più degli attributi sopra descritti,
rispetto alle modalità di fallimento previste per il sistema. Se i modi di fallimento previsti sono specificati e limitati, si parla di sistemi fail-controlled; un
sistema i cui fallimenti sono limitati soltanto all’interruzione del servizio sono
chiamati fail-stop o fail-silent. I sistemi fail-safe, invece, sono quelli per cui i
fallimenti possibili sono solamente fallimenti non catastrofici.
\begin{comment}
Il grado con cui un sistema possiede questi attributi deve essere interpre-
tato in senso probabilistico e non in senso assoluto, deterministico: a causa
dell’inevitabile occorrenza dei guasti i sistemi non sono mai totalmente di-
sponibili, affidabili, safe o secure. Per questo gli attributi di dependability
possono essere definiti in senso probabilistico cosi da poterli trattare in modo
quantitativo.
Ad esempio:
\begin{itemize}
\item L’affidabilità può essere rappresentata dalla probabilità che il sistema
non fallisca durante il periodo di missione del sistema. Se si assumono
distribuzioni esponenziali, possiamo rappresentare l’affidabilità tramite
il tasso di fallimenti (ad esempio, in numero medio di fallimenti all’ora).
\item La disponibilità è la probabilità che il sistema sia operativo al tempo t,
considerando l’alternanza fra gli stati di servizio corretto e servizio non
corretto.
\item La manutenibilità può essere rappresentata dalla velocità con cui viene
ripristinato un servizio corretto dopo un fallimento.

\end{itemize}
**guarda se aggiungere ultima parte con le formule
\end{comment}
\subsubsection{I mezzi per ottenere la dependability}
Lo sviluppo di sistemi dependable richiede l’utilizzo combinato di quattro
tipologie di tecniche:
\begin{itemize}

\item \textbf{prevenzione dei guasti}, per prevenire l’occorrenza o introduzione di
guasti nel sistema;
\item \textbf{tolleranza ai guasti}, per erogare un servizio corretto anche in presenza
di guasti;
\item \textbf{rimozione dei guasti}, per ridurre il numero o la gravita’ dei guasti;
\item \textbf{previsione dei guasti}, per stimare il numero di guasti presenti nel
sistema, la loro incidenza futura, o le loro probabili conseguenze.

\end{itemize}
\subparagraph{Prevenzione dei guasti}

La “Fault Prevention” viene effettuata ricorrendo a tecniche e processi di controllo di qualita’ sia durante la progettazione del software che durante la produzione dei componenti hardware.\begin{comment} Queste tecniche comprendono ad esempio
la programmazione strutturata e modulare, l’uso di linguaggi fortemente tipati, di editori guidati dalla sintassi e compilatori certificati per quanto riguarda
il software, mentre per quanto riguarda l’hardware l’uso di rigorosi processi
produttivi e di strumenti per la progettazione come linguaggi di alto livello
(VHDL). Guasti di origine fisica vengono prevenuti tramite specifiche prote-
zioni, ad esempio dalle radiazioni e interferenze elettromagnetiche. Guasti
che originano da interazioni umane possono invece essere prevenuti tramite
un’appropriata formazione del personale, o la creazione di procedure di manu-
tenzione rigorose. Guasti originati da attacchi esterni possono essere prevenuti
tramite firewall e dispositivi di sicurezza simili.\end{comment}
\subparagraph{Tolleranza ai guasti}
La “Fault Tolerance” mira a preservare l’erogazione di un servizio corretto in
presenza di guasti attivi. Essa viene solitamente implementata tramite rilevazione di errori (error detection) e conseguente recupero dello stato del sistema
(system recovery). In particolare, la rilevazione degli errori origina un segnale
di errore all’interno del sistema; esistono due classi di tecniche di rilevazione
di errori: concurrent error detection viene effettuata durante l’erogazione del
servizio, preemptive error detection viene effettuata quando l’erogazione del
servizio è sospesa e controlla la presenza di errori latenti e guasti dormienti.
Il recupero dello stato del sistema trasforma uno stato che contiene uno o più
errori attivi (ed eventualmente guasti), in uno stato che non contiene errori
rilevati e guasti che possono essere nuovamente attivati. Il recovery consiste
in error handling e fault handling. Error handling elimina gli errori dallo
stato del sistema e può assumere tre forme: rollback, dove la trasformazio-
ne consiste nel ritornare ad uno stato in cui si trovava il sistema prima della
rilevazione dell’errore; rollforward, dove si porta il sistema in uno stato del
tutto nuovo, e compensation, dove lo stato contiene abbastanza ridondanza
per eliminare la parte erronea. Fault handling impedisce che i guasti che sono
stati localizzati vengano nuovamente attivati, attraverso quattro fasi:
\begin{itemize}
\item \textbf{fault diagnosis} identifica l’origine della cause degli errori, in termini di
locazione e tipo;
\item \textbf{fault isolation} isola logicamente o fisicamente il componente, impedendogli di partecipare all’erogazione del servizio, trasformando il guasto in
un guasto dormiente;
\item \textbf{system reconfiguration} che riconfigura il sistema, ad esempio atti-
vando componenti di riserva o ridistribuendo il carico tra i componenti
funzionanti;
\item \textbf{system reinitialization}, che esegue i controlli e gli aggiornamenti ne-
cessari in seguito alla nuova configurazione.

\end{itemize}
Solitamente l’attività di fault handling è seguita da azioni di manutenzio-
ne correttiva, che rimuovono i guasti isolati dal fault handling, ad esempio
sostituendo un componente segnalato come guasto. Il fattore che distingue la
fault tolerance dalla manutenzione (maintenance) e’ che quest’ultima richiede
l’intervento di un agente esterno.
\subparagraph{Rimozione dei guasti}
La “Fault Removal” viene effettuata sia durante la fase di sviluppo, che durante la vita operazionale del sistema.
La rimozione dei guasti è uno degli obiettivi del processo di verifica e validazione (V\&V).
La verifica è un processo attraverso cui si determina se il sistema soddisfa alcune proprietà determinate dalle
specifiche o imposte all’inizio della fase di sviluppo; se cosi non è si cerca di
individuare il guasto che impedisce di soddisfare tali proprietà e lo si corregge.
La validazione consiste invece nel controllare se il sistema soddisfa le proprie
specifiche e se le specifiche descrivono adeguatamente la funzione intesa per il
sistema. Le tecniche di verifica possono essere classificate in base alla necessita’ di esercitare il sistema. La verifica di un sistema senza la sua esecuzione
è una verifica statica, altrimenti è una verifica dinamica. La rimozione dei
guasti durante la sua vita operazionale è manutenzione correttiva o preven-
tiva. La manutenzione correttiva ha l’obiettivo di rimuovere guasti che sono
stati segnalati come la causa di uno o più errori, la manutenzione preventiva
cerca di scovare e rimuovere i guasti prima che causino degli errori durante la
normale operazione del sistema.
\subparagraph{Previsione dei guasti}
La “Fault Forecasting” è condotta effettuando una valutazione del comporta-
mento del sistema rispetto all’occorrenza e attivazione dei guasti. La valuta-
zione puo’ essere di due tipi: qualitativa, che mira ad identificare, classificare
e valutare i modi di fallimento o le combinazioni di eventi che porterebbero ad
un fallimento del sistema; quantitativa (o probabilistica), che mira a valutare
in termini probabilistici il grado con cui alcuni attributi vengono soddisfatti
dal sistema; questi attributi sono in questo caso visti come misure. Alcuni
metodi di analisi sono specifici per una valutazione qualitativa o quantitativa, mentre altri possono essere utilizzati per entrambi i tipi di analisi. I due approcci principali per il fault forecasting di tipo probabilistico sono la modellizzazione e il testing. Questi approcci sono complementari: la costruzione di
un modello del sistema richiede delle informazioni su alcuni processi di base
del sistema, che possono essere acquisite tramite testing. Generalmente, un
sistema eroga diversi servizi, e spesso esistono due o più modi di erogazione
del servizio, ad esempio da servizio a pieno regime, a servizio di emergenza.
Questi modi distinguono la qualità o completezza del servizio erogato. Misu-
re di dependability collegate alla qualita’ del servizio erogato (performance)
vengono solitamente riassunte nella nozione di performability \cite{smith1988performability}.
I due principali approcci alla previsione dei guasti quantitativa sono la
costruzione di modelli e la loro soluzione (analitica o tramite simulazione), in
cui il comportamento del sistema è riprodotto tramite un modello (tipicamente
un modello stato-transizione), e la osservazione e la valutazione (anche tramite
test specifici) sperimentale. Le attività di fault injection sono un esempio di
valutazione sperimentale del sistema ai fini della fault forecasting, in quanto
permette di esaminare l’evoluzione e le conseguenze dei guasti in un sistema.


\subsection{Artificial Intelligence}
Nel pensiero comune quando si pensa al'intelligenza artificiale, si immagina un entità in grado di pensare, che prima o poi ci sostituirà. Nella realtà l'intelligenza artificiale è quella branca dell'Informatica che dato un determinato problema, definisce degli agenti che trovano in modo efficace le migliori soluzioni. Quindi il campo di  applicazione dell'intelligenza artificiale non è unico ma è suddiviso in sottodiscipline, dove si va da aree più generali come l'apprendimento e la percezione, ad altre più specializzate come il gioco degli scacchi e la dimostrazioni di teoremi matematici.
\subsubsection{Agente razionale,Misura di prestazione,Ambiente}

Nello specifico l'intelligenza artificiale si occupa di progettare \textbf{agenti razionali}, che posti in un \textbf{ambiente}, riescano a massimizzare la propria \textbf{misura di prestazione}.\cite{russell2005intelligenza}
Un \textbf{agente} è definito  come un sistema che percepisce il suo ambiente attraverso dei sensori e agisce su di esso mediante attuatori. Per farsi un idea, si può assumere che l'essere umano sia un agente, che fornito di sensori, come occhi,orecchie e altri organi, sente l'ambiente circostante, e attraverso altrettanti organi, come mani,gambe e bocca, interagisce con l'ambiente o altri agenti.(attuatori)
Un agente fisico, come una macchina a guida autonoma, ha sensori come: telecamere, sensori a infrarossi,radar e tanti altri, mentre come attuatori: motori,freni, e tanti altri. 
Un altra cosa che accomuna tutti gli agenti, sono le  \textbf{percezioni}, termine usato per indicare gli input percettivi dell'agente in dato istante.\cite{russell2005intelligenza}
La totalità delle percezioni generate dall'agente in tutta la sua storia, è definità invece come \textbf{sequenza percettiva}, dove in generale la scelta dell'azione di un agente in un qualsiasi istante puo dipendere dall'intera sequenza percettiva osservata fino a quel momento.
In termini matematici la rappresentazione del comportamento di un agente, è descritto dalla \textbf{funzione agente}, che descrive la corrispondenza tra una qualsiasi sequenza percettiva e una specifica azione.
Se la funzione agente è la rappresentazione matematica dell'agente, con il termine \textbf{programma agente} si indica la sua implementazione concreta  in  esecuzione sull'architettura dell'agente.  \cite{russell2005intelligenza}
\subsubsection{Agenti che apprendono}
Si definisce un agente sta imparando se migliora le proprie prestazioni nelle attività future dopo aver effettuato le osservazioni
sul mondo. \cite{russell2005intelligenza}
E perchè deve imparare?
Un agente deve impare per tre motivi:
\begin{itemize}
\item  il programmatore non può anticipare tutte le possibili situazioni che l'agente si potrà trovare davanti.
\item il programmatore non può anticipare tutti i cambiamenti nel tempo.
\item il programmatori spesso non sanno come programmare loro la soluzione a un problema.
\end{itemize}\cite{russell2005intelligenza}

Detto ciò, come esistono agenti diversi, per problemi diversi, esistono apprendimenti diversi per ogni agente, che possono essere applicati alle varie componenti dell'agente.
Una loro classificazione si basa su 4 fattori:
\begin{itemize}
\item \textbf{componente} dell'agente migliorata.
\item \textbf{rappresentazione} usata per i dati e i componenti
\item \textbf{prior knowledge} dell'agente presente.
\item \textbf{feedback}  disponibili da apprendere. 
\end{itemize} 



Esistono tre grosse tipologie di feedback che determinano i tre principali tipi di apprendimento:
\subparagraph{unsupervised learning}, dove un agente apprende patterns dall'input senza feedback espliciti. 

\subparagraph{reinforcement learning}, dove un agente apprende da una serie di rinforzi, punizioni o premi.
\subparagraph{supervised learning}, dove ha un agente sono forniti coppie di valori input-output e apprende una funzione che mappi dall'input all'output. 
Nello specifico, il compito di un apprendimento supervisionato è quello che dato un training set di N esempi della forma input-output

(x1.y1),(x2,y2),...(xn,yn),
dove ogni valore y è generato da un funzione sconosciuta y=f(x), questa scopre una funzione h che approssima la funzione f.  
Il Learning problem si può definire in due maniere a seconda del l'output y: nel caso in cui  y è uno di  un insieme finito di valori il problema è definito  \textbf{classificazione} (binaria o booleana, nel caso di due sole scelte),mentre se y è un numero
 si definisce come \textbf{regressione}


\subsubsection{Neural Network}
Una particolare forma di supervised learning, come ci suggerisce il titolo del seguite capitolo, sono le artificial neural network o più brevemente neural network. 
La \textbf{rete neurale} è composta da un insieme di nodi o unità connesse da link orientati.\cite{russell2005intelligenza}
 La topologia e le propietà dei nodi determina le proprietà della rete.
\subparagraph{Neurone}
Ciascun neurone o nodo, ha un insieme di input e produce un singolo output che può essere inviato a un gruppo di altri neuroni. Questo si attiva quando quando una combinazione lineare dei suoi input superano la sua hard o soft threshold. L'output dei neuroni finali sarà il risultato della task.
\subparagraph{Collegamenti}
Un link tra una unita i e un unità j serve a propagare l'attivazione $a_{i}$ da i a j. Oltretutto ogni collegamento ha anche un peso numerico $w_{i,j}$ associato, il quale determina la forza e il segno della connessione.
\subparagraph{funzione di attivazione}
In generale un neurone, calcola una somma pesata dei suoi input:
\[in_j=\sum_{i=0}^n  w_{i,j}a_{i}\]
A questa è applicata la \textbf{funzione di attivazione} g, dalla quale si deriva l'output:
\[a_j=g(in_j)=g \Bigl (\sum_{i=0}^n  w_{i,j}a_{i} \Bigr )\]
Nel caso in cui la funzione di attivazione è una hard threshold, l'unità è chiamato \textbf{perceptron}, nel caso in cui questa sia una funzione logica, si usa il termine \textbf{sigmoid perceptron}.
\subparagraph{feed-forward network}
Definito il modello matematico di ogni neurone, questi si connetteranno insieme, a formare una rete.
Esistono due principali tipologie: 
la \textbf{feed-forward network}, prevede connessioni solo in una direzione, formando un DAG, directed acyclic graph. Ogni nodo riceve gli input dai nodi superiori e invia gli output a nodi inferiori. Non sono previsti cicli. Questa tipologia di rete, rappresenta una funzione del corrente input, senza mantenere al suo interno, nessun tipo di stato se non i pesi dei collegamenti.
Il \textbf{recurrent network}, prevede che i suoi neuroni usino il proprio output come feedback per il proprio input, cosi che i livelli di attivazione della rete formano un sistema dinamico che raggiunge uno stato stabile o
esibiscono oscillazioni o addirittura comportamenti caotici. Questa caratteristica, permette alla rete di supportare un memoria a breve termine.
\begin{comment}
\subparagraph{perceptron network}:
Una forma semplice di feed-forward network, è il perceptron network o anche chiamato single-layer neural networl. Questo prevede che i suoi neuroni di input siano direttamente connessi a quelli di output. 
\end{comment}

\subsubsection{Convulutional Neural Network}
Una rete neurale convuluzionale è una rete neurale di tipo feed-forward network dove la strato convuluzionale compare almeno una volta.
L'input di una convulutional neurale network o ConvNet,\begin{comment} è ampiamente utilizzata nelle applicazioni di visione artificiale,\end{comment}, è una immagine, ossia una matrice di valori di ogni singolo pixel occupante una precisa posizione all'interno dell'immagine.Nel caso di immagini RGB, questa sarà descritta da un terna di matrici dell'intensità dei colori primari (rosso,verde,blu), nel caso di immagini in bianco e nero, queste sono descritte da una singola matrice. Le matrici che compongono le immagini, identificano i \textbf{canali} per la rete. Questa con le dimensioni dell'immagine,(heigth e width) compongono l'input della rete.
\subparagraph{L'architettura} 
Le reti neurali convoluzionali operano su strutture a griglia contraddistinte da relazioni spaziali tra pixel, ereditate da uno strato al successivo tramite valori che descrivono
piccole regioni locali dello strato precedente. L’insieme di matrici degli strati nascosti (hidden), risultato della convoluzione o di altre operazioni, è definita feature map o
activation map, i parametri addestrabili sono tensori denominati filtri o kernel.
Una CNN è composta da  un insieme di strati che si susseguono, illustrati in dettaglio nei paragrafi seguenti. Gli strati principali sono:
\begin{itemize}
\item convolutional layer;
\item activation layer;
\item pooling layer;
\item dense layer;
\end{itemize}
\cite{torresin2019sviluppo}

\subparagraph{Convolutional layer}
La convoluzione è l’operazione fondamentale delle ConvNet. Essa dispone un filtro in ogni possibile posizione dell’immagine, coprendola interamente, e computa il prodotto scalare tra il filtro stesso e la matrice corrispondente del volume di input, avente
eguale dimensioni. È possibile visualizzare la convoluzione come una sovrapposizione del kernel sull’immagine in input (o strato nascosto). \cite{aggarwal2018neural} 
Un filtro è caratterizzato dai
seguenti iperparametri (hyperparameters):
\begin{itemize}
\item altezza Fq
\item larghezza Fq
\item profondità d
\item numero q
\end{itemize}
Solitamente i filtri hanno forma quadrata e profondità uguale a quella dello strato al
quale sono applicati, nel caso di immagini RGB, 3. \begin{comment}Per un’immagine RGB,  per esempio il primo filtro convoluzionale
F*F*d potrà avere dimensione  5*5*3 o 7*7*3.\end{comment} Il numero di possibili
allineamenti tra filtro e immagine definisce altezza e larghezza della successiva feature
map.
Dal hidden layer q1, il filtro produce uno nuovo hidden layer q2
Lq+1 = Lq - Fq + 1
Bq+1 = Bq - Fq + 1
Ad esempio, per immagini di dimensioni 32 * 32, un filtro 5 * 5 genera uno strato
nascosto 28 x 28.
È opportuno fare distinzione tra profondità del filtro e profondità di strato nascosto/mappa di attivazione: la prima, d è la stessa dello strato al quale è applicato, la
seconda deriva invece dal numero di filtri applicati. Il numero di filtri è un iperparametro definito sulla base della capacità di distinguere forme sempre più complesse che
si vuole conferire alla rete. I filtri sono dunque i componenti a cui saranno associate le
caratteristiche dei pattern delle immagini.
I filtri dei primi strati individuano forme primitive, quelli successvi imparano a distinguere forme sempre più grandi e complesse. Una proprietà della convoluzione è
l’\textbf{equivarianza alla traslazione}: immagini traslate sono interpretate allo stesso modo e
i valori delle mappa di attivazione traslano con i valori di input \cite{torresin2019sviluppo}. Ciò significa che forme particolari generano feature maps simili, indipendentemente dalla loro collocazione
nell’immagine.
Una delle proprietà della convoluzione è la seguente:
	 Una convoluzione sullo strato
q incrementa il campo recettivo di una feature dallo strato q allo strato q + 1. In altre parole, ogni valore della mappa di attivazione dello strato successivo cattura una regione
spaziale più ampia del precedente. Feature maps degli strati catturano aspetti caratteristici di regioni via via maggiori e questo è il motivo per cui le CNN possono essere
definite “profonde”: per studiare l’intera immagine sono necessarie lunghe successioni
di “blocchi” di strati. 
In figura, un esempio dell’operazione di convoluzione.

\subparagraph{Padding} L’operazione di convoluzione comporta una contrazione dello strato q rispetto a q + 1 ed una conseguente perdita di informazioni. Il problema può essere
arginato utilizzando il cosiddetto padding, una tecnica che prevede l’aggiunta di $\frac{(Fmeno1)}{2}$ pixel ai bordi delle mappe di attivazione per mantenere l’impronta spaziale. Ovviamente, 
per non alterare l’informazione, ai pixel sono assegnati valori nulli. Il risultato
\cite{aggarwal2018neural} è un incremento delle dimensioni (altezza e larghezza) del volume di input di F - 1,
esattamente la quantità di cui è ridotto a seguito della convoluzione.
Essendo il prodotto zero, le regioni esterne soggette a padding non contribuiscono al risultato finale del prodotto scalare. Ciò che invece accade è permettere al filtro convoluzionale di scavalcare i bordi dello strato e computare il prodotto scalare
solamente per le celle di valori diversi da 0. Questa tipologia di padding è definita
“half-padding” in quanto circa metà del filtro oltrepassa i bordi, quando collocato alle
estremità. L’half-padding è utilizzato per mantenere il “footprint” spaziale.
Quando il padding non è utilizzato, si parla semplicemente di valid-padding e nella
pratica non dà buoni risultati per il seguente motivo: mentre con l’half-padding le
celle ai bordi contribuiscono all’informazione, nel caso di valid-padding, queste non
vedono il passaggio del filtro e sono sotto-rappresentate.
Un’altra forma di padding è il full-padding, con il quale si lascia che il filtro esuli
completamente dal layer andando ad occupare celle di soli zeri. Così facendo si incrementa l’impronta spaziale dello strato, allo stesso modo in cui il valid-padding la
riduce.\cite{aggarwal2018neural} 
\begin{comment}
\subparagraph{Strides} Un filtro convoluzionale computa il prodotto scalare in ogni singola posizione dello strato di input ma è altresì possibile limitare la computazione ad un numero
inferiore di posizioni, facendo uso dello stride S. La convoluzione è allora applicata
alle posizioni 1, S + 1, 2S + 1 etc., lungo entrambe le dimensioni. L’output avrà altezza
e larghezza, rispettivamente:
Lq+1 = Lq - F/S+ 1
Bq+1 = Bq - F/S+1
Ne consegue che lo stride comporta una riduzione delle dimensioni di un fattore
di circa 1/S, e dell’area di S alla seconda 2. Generalmente si usano valori limitati a 1 o 2 mentre con
stride maggiori si punta alla riduzione della richiesta di memoria. Tramite lo stride è
possibile catturare pattern complessi in vaste porzioni di immagine, con risultati simili
a quelli prodotti dal max-pooling.
In genere le dimensioni delle immagini in input sono ridotte a L = B, per evitare complicazioni nella definizione degli iperparametri. Per quanto concerne la convoluzione,
il numero di filtri è solitamente potenza di 2 per facilitare la computazione, lo stride di
1 o 2, le dimensioni del filtro di 3 o 5. Filtri piccoli significano reti più profonde e più
performanti.
Ogni filtro convoluzionale è infine associato ad un bias: dato un filtro p, ed il layer
q, bias è indicato con b(p, q). Il bias è un fattore di moltiplicazione della mappa di
attivazione e la sua presenza incrementa il numero di parametri di un’unità. Il numero
di features in ogni strato sarà dunque 1 + L x B x d. Come tutti gli altri parametri, il
valore del bias è definito tramite retropropagazione in fase di addestramento. \cite{aggarwal2018neural}\end{comment}
\subparagraph{Funzione di attivazione Relu}
L’operazione di attivazione non-lineare segue l’operazione di convoluzione. Per ogni
strato Lq x Bq x d, la funzione di attivazione genera uno strato di eguale dimensione
Lq x Bq x d di valori limitati da soglie: in quanto semplice mappatura uno-a-uno dei
valori di attivazione, la funzione ReLU non altera l’importa spaziale dello strato.
L’attivazione avviene tramite funzioni matematiche. Mentre in passato la tangente iperbolica, la funzione sigmoide, softsign godevano di ampia diffusione, ora sono
limitate a reti non-profonde e ormai rimpiazzate dalla funzione di attivazione ReLU
(Rectified Linear Unit). Il motivo principale è che in reti neurali profonde, il gradiente
di queste tre funzioni di attivazione si annulla durante la retropropagazione ed impedisce all’algoritmo di proseguire con l’addestramento. Inoltre, la funzione ReLU è
computazionalmente molto più efficiente. ReLU è definita come segue:


ReLU è di fatto una funzione di rimozione di valori negativi rivelatasi efficace ed efficiente: la sua derivata in IR+ è sempre 1 e non satura in IR; in altre parole, il codominio
della funzione è [0, inf). In corrispondenza dell’origine, la funzione non approssima
l’identità e genera invece un gradiente elevato impedendone la scomparsa. \cite{aghdam2017guide}
\subparagraph{Pooling layer}
Il max-pooling estrae il massimo valore contenuto in matrici P x P di ogni mappa di
attivazione e produce un altro hidden layer di eguale profondità. Anche in questo caso,
come per la convoluzione, si fa uso di stride: se lo stride è 1 lo strato 2 così generato
avrà dimensioni:
L2 = L1 - P + 1
B2 = B1 - P + 1
d2 = d1.
Per stride maggiori di 1, come solitamente si usa, altezza e larghezza saranno, rispettivamente:
L2 = L1 - P/S + 1
B2 = B1 - P/S+ 1
Rispetto alla convoluzione, il pooling è effettuato al livello di ciascuna mappa di attivazione, quindi il loro numero rimane alterato e l’output è uno strato della stessa profondità (ma di altezza e larghezza differenti). Una configurazione tipica è dimensione
2x2 e stride 2: così facendo non c’è sovrapposizione tra regioni.

L’uso dello stride nel pooling è importante per tre motivi. Il primo è la riduzione
dell’impronta spaziale delle mappe di attivazione, il secondo è un certo grado di invarianza alla traslazione e il terzo è un incremento del campo ricettivo. Si osservi che per
ridurre l’impronta spaziale possono essere utilizzati unicamente strati convoluzionali
con stride maggiori di 1. Nonostante ciò, si preferisce tuttora utilizzare max-pooling o
qualche altra variante dato il grado di non-linearità e invarianza alla traslazione che
introducono.\cite{aggarwal2018neural}
\subparagraph{dense layer}
Connette ogni feature in input con la corrispondente feature in output. Presenta la struttura di una rete feed-forward tradizionale e aumenta a dismisura il numero di parametri
addestrabili per effetto del numero di connessioni. Ad esempio, se due strati completamente connessi hanno 4096 unità ciascuno, il numero di connessioni (quindi di
parametri) sarà superiore a 16 milioni. \cite{aggarwal2018neural}



\subsection{Autonomous Driving}
Nell’ultimo decennio, il settore dell’Automotive è stato in continua evo-
luzione. In particolar modo, le grandi aziende automobilistiche e mol-
ti gruppi di ricerca si sono mossi verso l’automazione della guida ed
il miglioramento delle infrastrutture già esistenti. I motivi di questo
interessamento del settore verso la guida autonoma sono vari:
\begin{itemize}
\item riduzione del numero di incidenti, anche fino al 90%,
\item  riduzione dei consumi,
\item  riduzione delle emissioni di CO 2 ,
\item  nonché la riduzione di tutte le varie problematiche della sicurezza
stradale.

\end{itemize}
\subsubsection{Livelli di automazione della guida}
La SAE International, un ente di standardizzazione automobilistica,  nel 2014, pubblica un nuovo standard internazionale, il J3016 ("Levels of Driving Automation").
In questo sistema di classificazione, all’aumentare del livello di automa-
zione, la responsabilità del conducente passa dalla guida alle attività di
supervisione.
Lo standard suddivide l'automazione in 6 livelli, dal livello 0, in cui non è presente nessuna  automazione, al livello 5, dove il sistema guida in maniera completamente autonoma.
\begin{itemize}
\item Livelli 0:
Veicoli privi di qualsiasi sistema di automazione.
\item Livello 1: 
Veicoli  i quali mettono a disposizione dell'autista, almeno un sistema di assistenza, per esempio, l'assistenza alla frenata.
\item Livello 2:
Veicoli i quali cobinano due o più sistemi avanzati di assistenza alla guida, come l'adaptive cruise control, Lane-Keeping assist, e l'Automatic Emergency Braking. Tutti questi rientrano sotto la dicitura ADAS (Advanced Driver-Assistance Systems). Un 
\item Livello 3:
Veicoli definiti a guida semi-autonoma, siccome sono in grado di  gestire situazioni variegate, anche al di fuori di un contesto autostradale. Nel senso che si prendono la responsabilità di gestire tratti del tragitto, richiedendo però alla fine di questi la ripresa del controllo da parte del conducente. Nel caso questo non avvenisse, fermeranno nella maniera più sicura il  veicolo
\item Livello 4
Veicoli definiti a guida autonoma, sono dotati di un set di tecnologie in grado di procedere per lunghi tragitti, superando una varietà di ostacoli, come i caselli autostradali.Tuttavia il loro funzionamento sarà limitato:
• ad una determinata area geografica,
• da condizioni meteo avverse,
• da una velocità massima e così via.
\item Livello 5
Veicoli privi di qualsiasi limite e conducente, capaci di procedere in qualsiasi condizione e luogo
\end{itemize}
Al momento la serie di veicoli con il livello più alto, è l'Autopilot di Tesla, che effettivamente di può ritenere di livello 4, ma per motivi legali è categorizzato come livello 3, e la navetta Olly, classificata come livello 4.

\subsubsection{Visione artificiale}
Come definito nella sezione precedente dedicata all'intelligenza artificiale, ogni agente prende in input una sensazione, la elabora, prende una decisione, e la attua con gli attuatori. Applicando questo concetto all'autonomus driving, anche questi hanno una serie di sensori, che gli permettono di prendere coscienza dell'ambiente circostante in cui è immersa la vettura.
Le principali tecnologie, presenti al momento su questi sistemi sono\cite{das2018risk}:
\begin{itemize}
\item Videocamere,
\item Radar,
\item Lidar,
\item GPS.
\end{itemize}
che insieme compongono la visione artificiale avanzata dell'autonomus driving.
Tutte insieme, forniscono un modello del ambiente circostante (3D),  attraverso immagini bidimensionali(2D).
Lo scopo della visione artificiale è proprio quella di riprodurre la vista umana.\cite{wiki:visart}
Come pre-annunciato il seguente elaborato prenderà definirà un detector dei guasti sulla fotocamera. Questa scelta è data dal fatto che sui veicoli
di oggi sono presenti più dispositivi di questo genere ed il loro obiettivo
è catturare i fotogrammi e renderli disponibili come input per software
impiegati nella scelta del comportamento da tenere.
\subparagraph{LIDAR - Light Detection And Ranging}
Il Lidar è  solito essere installato sul tettuccio del veicolo, è un sensore che attraverso l'emissione e ricezione di segnali luminosi, laser, ottiene informazioni fisiche  dell'ambiente e  cinematiche sul  veicolo.
\begin{comment}
È una tecnologia di telerilevamento. I suoi usi sono molto vari soprattutto
perché il suo obiettivo principale è quello di raccogliere informazioni
3D e usare la luce sotto forma di un laser pulsato per misurare diverse
distanze. Il suo ruolo è quello di raccogliere informazioni cinematiche sul
veicolo e informazioni fisiche sull’ambiente circostante. Il sensore ottico
LIDAR è installato sul tettuccio del veicolo autonomo. È composto da un
laser, un filtro per obiettivo, un ricevitore, un regolatore di potenza, uno
specchio rotante e un processore integrato \citep{das2018risk}.
Diversamente dal Radar, che al posto della luce utilizza onde radio,3.2 visione artificiale
la distanza dell’oggetto è determinata misurando il tempo trascorso fra
l’emissione dell’impulso e la ricezione del segnale retrodiffuso. L’unità
di elaborazione deve essere collocata in una posizione abbastanza rialza-
ta da terra; inoltre, sono necessarie misure di sicurezza per proteggere
l’unità da urti o vibrazioni derivanti da incidenti o dalla navigazione su
terreni accidentati, che potrebbero causare guasti al sistema.
\end{comment}
\subparagraph{RADAR - RAdio Detection And Ranging}
E' un sistema che utilizza onde radio trasmesse nell'ambiente, al fine di raccogliere informazioni sugli  ostacoli intorno al veicolo e aumentare la consapevolezza del  posizionamento degli altri veicoli presenti. Questo sensore tiene
d’occhio le altre auto e indica all’auto autonoma di accelerare o rallentare
a seconda del comportamento degli altri conducenti \cite{das2018risk}.
\begin{comment}
È un sistema che utilizza onde radio per il rilevamento e la determina-
zione della posizione ed eventualmente della velocità di oggetti fissi o
mobili, come aerei, navi, veicoli, formazioni atmosferiche o il suolo. Le
onde radio vengono trasmesse nell’ambiente per raccogliere informazioni
sugli ostacoli intorno al veicolo e aumentare la consapevolezza del po-
sizionamento degli altri soggetti davanti e dietro. Questo sensore tiene
d’occhio le altre auto e indica all’auto autonoma di accelerare o rallentare
a seconda del comportamento degli altri conducenti \cite{das2018risk}.
È utile anche per posteggiare il veicolo ed in questo caso si sente parlare
di sensori anteriori e posteriori.
\begin{end}
\subparagraph{Videocamera}
Le telecamere sono necessarie nel sistema di trasporto intelligente affinché si riconoscano gli ostacoli rispetto alla posizione e alla velocità del
veicolo in considerazione. Le immagini bidimensionali derivanti da una
singola fotocamera o le mappe 3D risultanti dall’utilizzo della doppia
fotocamera, potrebbero individuare stereoscopicamente lo spazio disponibile per i movimenti autonomi del veicolo. Queste immagini o mappe
vengono utilizzate per estrarre informazioni quantitative dalle scene e
per tracciare gli obiettivi del veicolo. Le immagini sono segmentate in un
certo numero di pixel. Ogni pixel viene elaborato e memorizzato, il che richiede un’elevata velocità di calcolo ed un elevato spazio di archiviazione
\cite{das2018risk}.

\subparagraph{GPS - Global Positioning System}
Il Sistema di Posizionamento Globale, attraverso una rete dedicata di sa-
telliti artificiali in orbita, fornisce a un terminale mobile o ad un ricevitore
GPS informazioni sulle sue coordinate geografiche e sul suo orario in
quasi tutte le condizioni atmosferiche ed ovunque non vi siano ostacoli
che potrebbero impedirne l’invio e la ricezione dei segnali (edifici molto
alti, gallerie, ecc.), generando errori dell'ordine di metri.
\begin{comment}
La localizzazione avviene tramite la trasmissione di un segnale radio da parte di ciascun satellite e l’elaborazione dei
segnali ricevuti da parte del ricevitore \cite{das2018risk}
Per far procedere autonomamente il veicolo, il GPS, con l’aiuto di altri
sensori, crea mappe precise della carreggiata e guida nella direzione
esatta. 
\end{comment}
\subsubsection{Reti neurali applicate all'autonomus driving}
Le Reti Neurali sono oggi ampliamente accettate come soluzioni dominanti per la visione artificiale, per il riconoscimento vocale e per l’elaborazione del linguaggio naturale. Nel campo della visione artificiale,le neural network elaborano le informazioni ottenute dai sensori, e ne estraggono informazioni utili al fine di prendere decisioni sul come muoversi, garantendo la sicurezza dei viaggiatori, e degl'utenti esterni al veicolo. 
Questo sistema presenta comunque delle criticità, come una non corretta interpretazione dell'ambiente a causa di guasti, che minano la sicurezza dei passeggeri, ma anche tutto ciò che circonda il veicolo, come un caso di autopilot di Tesla.
Per quanto riguarda le prestazioni misurate su questa tecnologia, sono stati
registrati punteggi di accuratezza spesso corrispondenti a quelli di un
individuo umano, su benchmark chiave. Ben diversi, invece, sono sta-
ti i punteggi osservati quando si considerano i casi peggiori. Con casi
peggiori si vuole intendere quei casi definiti Adversarial Examples \cite{engstrom2019exploring} o
input perturbati, anche solo leggermente, che dal punto di vista umano
risultano sempre comprensibili, mentre da quello della macchina, cam-
biano totalmente di significato. Naturalmente, se queste Reti vengono
utilizzate su veicoli che devono muoversi in un ambiente nel quale si
trova un’eterogeneità di soggetti e comportamenti, si parla di contesti
nei quali affidabilità, sicurezza e tutti gli altri attributi che definiscono la
dependability di un sistema sono al primo posto in ordine di importanza.

\subsubsection{Classificatori}
Una attività importante delle reti neurali nella guida autonoma, è il processo di classificazione; ovvero l'identificazione di particolari caratteristiche  intrinseche di un insieme di immagini o fotogrammi, sulle quali prenderà delle decisioni.
Come detto in precedenza, le reti neurali presentano delle criticità in presenza di immagini prese in input trasformate spazialmente \cite{engstrom2019exploring}: con
questo termine si intende rappresentare tutte le possibili trasformazioni
che un’immagine può subire, ad esempio ruotandola, tagliandola, sca-
landola ecc. Queste sono trasformazioni naturali e sono utilizzate in vari
contesti:
• verificare il livello di completezza di un classificatore,
• allenare una rete neurale,
• ricreare scenari o situazioni con cui il veicolo su cui è installata una
determinata rete può avere a che fare.
Con il termine "trasformata spazialmente" non ci si deve immaginare
una modifica profonda del fotogramma in questione, ma anzi, basta
anche solo una piccola rotazione, di meno di un grado, per far sì che il
classificatore confonda, ad esempio, un revolver con una trappola per topi
\cite{engstrom2019exploring}, il che, pensando ad un utilizzo anche diverso da quello che se ne fa
su un veicolo a guida autonoma, può far sorgere molte preoccupazioni e
domande (si pensi all’ambito aeroportuale).

\subsubsection{Object Recognition}
In generale, ci si riconduce al problema dell’Object Recognition o ricono-
scimento artificiale degli oggetti. Questo richiede che ci sia una nozione
di somiglianza visiva, difficile da far apprendere ad un sistema: signifi-
cherebbe catturare e insegnare ad una macchina la nozione di percezione
umana \cite{engstrom2019exploring}.
\begin{comment}
Tuttavia, oggi, le DNN (Deep Neural Network) hanno raggiunto presta-
zioni all’avanguardia, talvolta competitive con la percezione umana.
Una della sfide principali nella guida autonoma è il cambiamento am-
bientale che un qualsiasi sistema autonomo può incontrare, ovvero: le
differenti distanze e angolazioni con cui viene percepito l’ambiente circo-
stante dai sistemi di visione artificiale variano ogni volta che il veicolo si
muove nello spazio [34].
Purtroppo, nel contesto della guida autonoma, anche un piccolo errore
di valutazione nella navigazione potrebbe causare incidenti altamente
devastanti.
Figura 8.: Schema training e impiego della Rete Neurale su un veicolo
Diversi gruppi di ricerca hanno sviluppato un modello preliminare di
analisi del rischio per veicoli autonomi. In tali studi sono stati considerati
dei sottosistemi di veicoli autonomi e/o alcuni componenti dell’infra-
struttura di trasporto; tuttavia, condizioni meteorologiche, altri utenti
della strada (guidatori non autonomi, ciclisti, pedoni, ecc.) e condizioni
della superficie stradale non sono state incluse [31].
\end{comment}

\subsection{CARLA}
\subparagraph{Autonomus driver simulator}
Lo sviluppo della guida senza conducente è un argomento attuale e di
grande interesse, su cui molte società automobilistiche stanno investendo
dato che promette di essere un mercato da miliardi di dollari [15].Di contro, la guida in ambiente cittadino è una sfida
molto più grande, per via del maggiore grado di variabilità degli scenari
che si possono presentare e degli oggetti che devono essere riconosciuti,
ed è necessario ancora molto lavoro prima che sia disponibile un sistema
in grado di muoversi da solo in questi ambienti senza pericolo e in modo
efficiente.
Nell’ottica dello sviluppo di un sistema di guida autonoma efficiente
e sicuro, si rende necessario lo sviluppo di metodi e strumenti per il
miglioramento dell’efficienza del prodotto e per la validazione dello
stesso. Tra le tecniche utilizzate per automobili a guida autonoma ci sono
metodi di apprendimento automatico che richiedono una gran quantità di
immagini, inoltre sia per lo sviluppo che soprattutto per la validazione, si
deve considerare che esistono una quantità infinita di scenari (situazioni)
che si possono presentare e che il sistema progettato deve essere in grado
di agire nel modo più sicuro in ognuno di essi. Il problema è di per sé mal
posto, visto che non è dato sapere se un’auto che reagisce correttamente
in una certa situazione farà lo stesso cambiando qualche variabile dello
scenario.
lo sviluppo e la validazione delle auto a guida autonoma si configura
per quanto detto come molto complicato e costoso, visto che è necessario
effettuare un gran numero di prove in diversi scenari.
Per aiutare a risolvere il problema dei costi dello sviluppo con testing
in ambiente fisico e della richiesta di dati che abbiamo presentato, sono
stati sviluppati dei simulatori che permettono di sperimentare il software
sviluppato in un ambiente virtuale, tra questi NVIDIA DRIVE Constella-
tion, AirSim, e CARLA Simulator. Questi simulatori riproducono scenari di guida cittadina
in cui è possibile testare un auto a guida autonoma che raccoglie dati
dall’ambiente. Per le considerazioni fatte in precedenza, un simulatore
si presenta come un alleato fondamentale nel processo di sviluppo e di
validazione. Infatti un simulatore in grado di riprodurre realisticamente
il complicato ambiente cittadino può essere utilizzato per lo sviluppo
con tecniche di machine learning avide di dati, per cui sono necessari
centinaia di migliaia di riproduzioni per ottenere risultati, e per testare il
sistema in altrettanti scenari, anche eticamente o fisicamente difficili da
riprodurre, prima o congiuntamente allo sviluppo e al testing su strada.

In particolare CARLA è un simulatore grafico open source costituito da un'architettura client-server scalabile.
dove il server è responsabile  di tutto ciò che riguarda la simulazione dell'ambiente in tutti i suoi aspetti: rendering del sensore, calcolo della fisica, aggiornamenti sullo stato del mondo e sui suoi attori e molto altro. 
Mentre il lato client consiste in una somma di moduli client che controllano la logica degli attori sulla scena e impostano le condizioni del mondo. 
\subsubsection{Sensori}
Come un veicolo reale di guida autonoma, CARLA predispone una suite di sensori dell'agente oltre a configigurazioni flessibili e integrazioni di ulteriori.
 I sensori pre-esistenti sono le fotocamere RGB e i  pseudo-sensori
che forniscono ground-truth depth e ground-truth semantic segmentation .
Il numero di telecamere ed il loro tipo e posizione possono essere specificati dal cliente. I parametri della fotocamera includono la posizione 3D,
l’orientamento 3D rispetto al sistema di coordinate dell’auto, al campo
visivo e alla profondità di campo. 
\section{Costruzione del dataset}
Siccome il detector impiega la CNN,  come strumento per l'identificazione di guasti nel sensore della telecamera del veicolo, è necessario istruire il sistema alla loro identificazione. Per fare questo , è necessario predisporre un dataset su cui  istruire il sitema.
Per costruire questo, si necessità l'acquisizione  di immagini simili a  quelle ottenibili da una telecamera posto su una vettura.
Nel caso della seguente tesi, il classificatore è  di tipo binario, quindi classifica le immagini tra pulite o sporche, quindi a sua volta il dataset sarà  suddiviso in due classi o label.  

\subparagraph{Acquisizione}
La scelta di utilizzare una soluzione software per la simulazione di una 







Detto ciò, la prima cosa che è necessario predisporre è il dataset di dati, da fornirgli. 
Nel caso di questa tesi, i detector sono implementati attraverso singoli classicatori binari, dove ciascuno è stato allenato ad apprendere singoli casi di malfunzionamento. 
Come spiegato precedentemente, le reti neurali prevedono due diversi dataset: il training set  e il validation set. 
Entrambi suddivisi in golden run e sporcate.

Quindi il dataset avrà la seguente forma, generale a tutti i malfunzionamenti presi in considerazione:
\begin{itemize}
\item Training set
\begin{itemize}
\item{Originale}
\item{Sporcata}
\end{itemize}
\item Validation set
\begin{itemize}
\item{Originale}
\item{Sporcata}
\end{itemize}
\end{itemize}
Dovendo ottenere un simil risultato, si è proceduto con le due seguenti fasi:
\begin{itemize}
\item Acquisizione;
\item Sporcatura;
\end{itemize}

\subparagraph{Acquisizione}
La prima fase del processo di costruzione del dataset  prevede l'acquisizione di immagini pulite dal simulatore CARLA. Attraverso il seguente software github, è stato possibile acquisire le immagini senza errori.
Sono state avviate 500 simulazioni diverse, dove da ciascuna sono state acquisite 300 immagini .png nella forma (800*600)
\begin{comment}
Nel caso di questo progetto il numero di simulazioni avviate è stato di 500, da cui per ciascuno sono state prodotte 300 immagini (800*600)
\end{comment}
\subparagraph{Sporcatura}
La seconda fase del processo di costruzione, prevede la "sporcatura" delle immagini salvate nella prima fase, immagazzinandole in maniera tale da essere poi usate dalla rete neurale.
Per "sporcatura" di una immagine, è inteso l'applicazione di un effetto all'immagine che simuli un guasto al sensore ottico della vettura.
Per fare questo è stato usato il progetto github "progetto secci".

\section{Costruzione del detector}
Per la  costruzione del detector,  è stata implementata una rete neurale convuluzionale. 
\begin{figure}[h!]
  \includegraphics[scale=0.1]{"cnnmodel"}
  \caption{CNN detector}
  \label{fig:CNN}
\end{figure}

Come si nota dalla figura ~\ref{fig:CNN}, questa è composta da un insieme di layer.
Il primo layer ha un è un conv2D layer, di ben 800*600*3=1440000 neuroni.
Le dimensioni di questo primo sono date dalla necessità di poter elaborare un immagine per intero, e infatti (800,600) sono le dimensioni di larghezza e altezza delle immagini, e quindi il numero di pixelche compongono l'immagine sono 800*600=480000,  l'ultimo fattore è dato dalla composizione interna di un pixel. Questo rappresenta il numero di canali dei colori,ed essendo immagini rgb (red,green,blue) sono 3.
Definito l'input del primo layer e quindi dell'intera rete, si può passare all'output.
   
\subsection{Addestramento del rete convuluzionale}




\section{Esecuzione e risultati}

\section{Conclusioni e lavori futuri}

\section{A Manuale utente}

\newpage
\printbibliography

\end{document}
